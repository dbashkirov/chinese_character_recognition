{\rtf1\ansi\ansicpg1251\cocoartf2639
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww28600\viewh17440\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs26 \cf0 \expnd0\expndtw0\kerning0
\{\
  "nbformat": 4,\
  "nbformat_minor": 0,\
  "metadata": \{\
    "colab": \{\
      "name": "chinese character recognition.ipynb",\
      "provenance": [],\
      "collapsed_sections": [],\
      "machine_shape": "hm"\
    \},\
    "kernelspec": \{\
      "name": "python3",\
      "display_name": "Python 3"\
    \},\
    "accelerator": "GPU"\
  \},\
  "cells": [\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "ZnE2JUV50Q0g",\
        "outputId": "fa2bc636-2ad4-4e99-fbc9-5e079fbe7c9e",\
        "colab": \{\
          "base_uri": "https://localhost:8080/",\
          "height": 53\
        \}\
      \},\
      "source": [\
        "%tensorflow_version 2.x\\n",\
        "import numpy as np\\n",\
        "import pandas as pd\\n",\
        "import tensorflow as tf\\n",\
        "import keras\\n",\
        "from keras import backend as K\\n",\
        "import numpy as np\\n",\
        "%matplotlib inline\\n",\
        "import matplotlib.pyplot as plt\\n",\
        "from google.colab import drive\\n",\
        "from skimage.transform import resize\\n",\
        "from keras.utils import to_categorical\\n",\
        "from tensorflow.keras.models import Sequential, Model\\n",\
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization, Input, ZeroPadding2D\\n",\
        "from tensorflow.keras.activations import relu\\n",\
        "from tensorflow.keras.layers import LeakyReLU\\n",\
        "from tensorflow.keras.models import load_model"\
      ],\
      "execution_count": null,\
      "outputs": [\
        \{\
          "output_type": "stream",\
          "text": [\
            "TensorFlow 2.x selected.\\n"\
          ],\
          "name": "stdout"\
        \},\
        \{\
          "output_type": "stream",\
          "text": [\
            "Using TensorFlow backend.\\n"\
          ],\
          "name": "stderr"\
        \}\
      ]\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "DxSUQruf745K",\
        "outputId": "72fd4774-4b8d-4d49-a85d-5d5bd4d9915d",\
        "colab": \{\
          "base_uri": "https://localhost:8080/",\
          "height": 127\
        \}\
      \},\
      "source": [\
        "drive.mount('/content/gdrive/')"\
      ],\
      "execution_count": null,\
      "outputs": [\
        \{\
          "output_type": "stream",\
          "text": [\
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\\n",\
            "\\n",\
            "Enter your authorization code:\\n",\
            "\'b7\'b7\'b7\'b7\'b7\'b7\'b7\'b7\'b7\'b7\\n",\
            "Mounted at /content/gdrive/\\n"\
          ],\
          "name": "stdout"\
        \}\
      ]\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "y1qYkJDGS2ls"\
      \},\
      "source": [\
        "data_train = np.load(\\"/content/gdrive/My Drive/train-1.npy\\", allow_pickle=True)\\n",\
        "for i in range(2, 5):\\n",\
        "    t = np.load(f\\"/content/gdrive/My Drive/train-\{i\}.npy\\", allow_pickle=True)\\n",\
        "    data_train = np.concatenate([data_train, t])\\n",\
        "data_test = np.load(\\"/content/gdrive/My Drive/test.npy\\", allow_pickle=True)"\
      ],\
      "execution_count": null,\
      "outputs": []\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "Bm1B9_1zGuXZ"\
      \},\
      "source": [\
        "X = data_train[:, 0]\\n",\
        "y = data_train[:, 1]"\
      ],\
      "execution_count": null,\
      "outputs": []\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "GyZZfuFzIbkl"\
      \},\
      "source": [\
        "mask = \{\}\\n",\
        "decoder = \{\}\\n",\
        "k = 1\\n",\
        "for i in y:\\n",\
        "  if not mask.get(i):\\n",\
        "    mask[i] = k\\n",\
        "    decoder[k] = i\\n",\
        "    k += 1"\
      ],\
      "execution_count": null,\
      "outputs": []\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "swSv4r6lS7Ur"\
      \},\
      "source": [\
        "def train_gen():\\n",\
        "  for img, label in data_train:\\n",\
        "    img = img[..., None]\\n",\
        "    yield img, mask[label]\\n",\
        "\\n",\
        "def val_gen():\\n",\
        "  for img, label in data_train[:int(len(data_train) * 0.3)]:\\n",\
        "    img = img[..., None]\\n",\
        "    yield img, mask[label]\\n",\
        "\\n",\
        "def test_gen():\\n",\
        "  for img in data_test:\\n",\
        "    img = img[..., None]\\n",\
        "    yield img"\
      ],\
      "execution_count": null,\
      "outputs": []\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "g6rQTUfj6tUJ"\
      \},\
      "source": [\
        "def augmentation(image):\\n",\
        "    image = tf.image.random_brightness(image, 0.2)\\n",\
        "    image = tf.image.random_crop(image, size=(128, 128, 1), seed=42)\\n",\
        "    return image\\n",\
        "\\n",\
        "def preprocess_train(image, label):\\n",\
        "    image = tf.cast(image, tf.float32)\\n",\
        "    image = (image / 127.5) - 1\\n",\
        "    #image = tf.image.resize(image, (153, 153))\\n",\
        "    #image = augmentation(image)\\n",\
        "    image = tf.image.resize(image, (96, 96))\\n",\
        "    #image = tf.image.grayscale_to_rgb(image)\\n",\
        "    label = tf.one_hot(label, 1000)\\n",\
        "    return image, label\\n",\
        "\\n",\
        "def preprocess_val(image, label):\\n",\
        "    image = tf.cast(image, tf.float32)\\n",\
        "    image = (image / 127.5) - 1\\n",\
        "    image = tf.image.resize(image, (96, 96))\\n",\
        "    label = tf.one_hot(label, 1000)\\n",\
        "    return image, label\\n",\
        "\\n",\
        "def preprocess_test(image):\\n",\
        "    image = tf.cast(image, tf.float32)\\n",\
        "    image = (image / 127.5) - 1\\n",\
        "    image = tf.image.resize(image, (96, 96))\\n",\
        "    return image"\
      ],\
      "execution_count": null,\
      "outputs": []\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "xp3AP6TP7UMb"\
      \},\
      "source": [\
        "batch_size = 128\\n",\
        "ds_train = tf.data.Dataset.from_generator(train_gen,\\n",\
        "                                          output_types=(tf.float32, tf.int32),\\n",\
        "                                          output_shapes=((None, None, 1), ())\\n",\
        "                                         ).map(preprocess_train, num_parallel_calls=-1).prefetch(-1).shuffle(1024).batch(batch_size).repeat()\\n",\
        "ds_val = tf.data.Dataset.from_generator(val_gen,\\n",\
        "                                          output_types=(tf.float32, tf.int32),\\n",\
        "                                          output_shapes=((None, None, 1), ())\\n",\
        "                                         ).map(preprocess_val, num_parallel_calls=-1).prefetch(-1).shuffle(1024).batch(batch_size).repeat()\\n",\
        "ds_test = tf.data.Dataset.from_generator(test_gen,\\n",\
        "                                          output_types=tf.float32,\\n",\
        "                                          output_shapes=(None, None, 1)\\n",\
        "                                         ).map(preprocess_test, num_parallel_calls=-1).prefetch(-1).batch(batch_size)"\
      ],\
      "execution_count": null,\
      "outputs": []\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "cyI3FkzK5idK"\
      \},\
      "source": [\
        "cols = 8\\n",\
        "rows = 2\\n",\
        "fig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\\n",\
        "for i in range(cols):\\n",\
        "    for j in range(rows):\\n",\
        "        random_index = np.random.randint(0, len(data_train))\\n",\
        "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\\n",\
        "        ax.grid(False)\\n",\
        "        ax.axis('off')\\n",\
        "        img, lbl = data_train[random_index]\\n",\
        "        img = img[..., None]\\n",\
        "        img, lbl = preprocess_train(img, mask[lbl])\\n",\
        "        print(img.shape)\\n",\
        "        ax.imshow(img)\\n",\
        "plt.show()"\
      ],\
      "execution_count": null,\
      "outputs": []\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "tIJYZMwS5s88"\
      \},\
      "source": [\
        "INIT_LR = 0.01\\n",\
        "EPOCHS = 40\\n",\
        "IMG_SIZE = 96\\n",\
        "NUM_CLASSES = 1000"\
      ],\
      "execution_count": null,\
      "outputs": []\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "aWCk-NevpxRN"\
      \},\
      "source": [\
        "def make_model():\\n",\
        "    model = Sequential()\\n",\
        "    model.add(Input(shape=(IMG_SIZE, IMG_SIZE, 1)))\\n",\
        "    model.add(ZeroPadding2D())\\n",\
        "    model.add(Conv2D(64, (3, 3), strides=(2, 2)))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(momentum=0.66))\\n",\
        "\\n",\
        "    model.add(ZeroPadding2D())\\n",\
        "    model.add(Conv2D(128, (3, 3)))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(axis=3, momentum=0.66))\\n",\
        "\\n",\
        "    model.add(ZeroPadding2D())\\n",\
        "    model.add(Conv2D(128, (3, 3)))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(axis=3, momentum=0.66))\\n",\
        "\\n",\
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\\n",\
        "\\n",\
        "    model.add(ZeroPadding2D())\\n",\
        "    model.add(Conv2D(256, (3, 3)))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(axis=3, momentum=0.66))\\n",\
        "\\n",\
        "    model.add(ZeroPadding2D())\\n",\
        "    model.add(Conv2D(256, (3, 3)))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(axis=3, momentum=0.66))\\n",\
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\\n",\
        "\\n",\
        "    model.add(ZeroPadding2D())\\n",\
        "    model.add(Conv2D(384, (3, 3)))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(axis=3, momentum=0.66))\\n",\
        "\\n",\
        "    model.add(ZeroPadding2D())\\n",\
        "    model.add(Conv2D(384, (3, 3)))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(axis=3, momentum=0.66))\\n",\
        "\\n",\
        "    model.add(ZeroPadding2D())\\n",\
        "    model.add(Conv2D(384, (3, 3)))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(axis=3, momentum=0.66))\\n",\
        "\\n",\
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\\n",\
        "\\n",\
        "    model.add(ZeroPadding2D())\\n",\
        "    model.add(Conv2D(512, (3, 3)))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(axis=3, momentum=0.66))\\n",\
        "\\n",\
        "    model.add(ZeroPadding2D())\\n",\
        "    model.add(Conv2D(512, (3, 3)))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(axis=3, momentum=0.66))\\n",\
        "\\n",\
        "    model.add(ZeroPadding2D())\\n",\
        "    model.add(Conv2D(512, (3, 3)))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(axis=3, momentum=0.66))\\n",\
        "    \\n",\
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\\n",\
        "\\n",\
        "\\n",\
        "    model.add(Flatten())\\n",\
        "    model.add(Dense(1024))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(momentum=0.66))\\n",\
        "    model.add(Dense(256))\\n",\
        "    model.add(LeakyReLU(alpha=0.01))\\n",\
        "    model.add(BatchNormalization(momentum=0.66))\\n",\
        "    model.add(Dense(1000))\\n",\
        "    model.add(Activation('softmax'))\\n",\
        "\\n",\
        "    return model"\
      ],\
      "execution_count": null,\
      "outputs": []\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "DHDgXpxzoc5O"\
      \},\
      "source": [\
        "model = make_model()\\n",\
        "\\n",\
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=INIT_LR),\\n",\
        "              loss='categorical_crossentropy',\\n",\
        "              metrics=['accuracy'])\\n",\
        "\\n",\
        "def lr_scheduler(epoch):\\n",\
        "  global INIT_LR\\n",\
        "  if epoch % 5 == 0:\\n",\
        "    INIT_LR *= .5\\n",\
        "  return INIT_LR"\
      ],\
      "execution_count": null,\
      "outputs": []\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "MEz7S6_uQSMe",\
        "outputId": "444dc2a4-c94f-4522-d4a5-165bb63ddb3b",\
        "colab": \{\
          "base_uri": "https://localhost:8080/",\
          "height": 35\
        \}\
      \},\
      "source": [\
        "model.load_weights('/content/gdrive/My Drive/weights_setmodel')"\
      ],\
      "execution_count": null,\
      "outputs": [\
        \{\
          "output_type": "execute_result",\
          "data": \{\
            "text/plain": [\
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f84aff97cf8>"\
            ]\
          \},\
          "metadata": \{\
            "tags": []\
          \},\
          "execution_count": 14\
        \}\
      ]\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "f_2qyri-n0sb",\
        "outputId": "9df4237b-d9c3-43bc-dbf5-c08424c3ce5a",\
        "colab": \{\
          "base_uri": "https://localhost:8080/",\
          "height": 1000\
        \}\
      \},\
      "source": [\
        "history = model.fit(ds_train,\\n",\
        "          epochs=EPOCHS,\\n",\
        "          steps_per_epoch=350,\\n",\
        "          callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)],\\n",\
        "          #validation_data=ds_val,\\n",\
        "          #validation_steps=20,\\n",\
        "          )"\
      ],\
      "execution_count": null,\
      "outputs": [\
        \{\
          "output_type": "stream",\
          "text": [\
            "Train for 350 steps\\n",\
            "Epoch 1/40\\n",\
            "350/350 [==============================] - 50s 143ms/step - loss: 3.2023 - accuracy: 0.3448\\n",\
            "Epoch 2/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.9091 - accuracy: 0.7502\\n",\
            "Epoch 3/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.4907 - accuracy: 0.8631\\n",\
            "Epoch 4/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.3434 - accuracy: 0.9015\\n",\
            "Epoch 5/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.2852 - accuracy: 0.9191\\n",\
            "Epoch 6/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.1645 - accuracy: 0.9546\\n",\
            "Epoch 7/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.1596 - accuracy: 0.9546\\n",\
            "Epoch 8/40\\n",\
            "350/350 [==============================] - 49s 140ms/step - loss: 0.0998 - accuracy: 0.9719\\n",\
            "Epoch 9/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0974 - accuracy: 0.9724\\n",\
            "Epoch 10/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.1744 - accuracy: 0.9507\\n",\
            "Epoch 11/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0854 - accuracy: 0.9776\\n",\
            "Epoch 12/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.0622 - accuracy: 0.9829\\n",\
            "Epoch 13/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.0648 - accuracy: 0.9830\\n",\
            "Epoch 14/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.1064 - accuracy: 0.9702\\n",\
            "Epoch 15/40\\n",\
            "350/350 [==============================] - 48s 139ms/step - loss: 0.0825 - accuracy: 0.9779\\n",\
            "Epoch 16/40\\n",\
            "350/350 [==============================] - 48s 139ms/step - loss: 0.0251 - accuracy: 0.9937\\n",\
            "Epoch 17/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0429 - accuracy: 0.9898\\n",\
            "Epoch 18/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.0374 - accuracy: 0.9920\\n",\
            "Epoch 19/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0316 - accuracy: 0.9928\\n",\
            "Epoch 20/40\\n",\
            "350/350 [==============================] - 48s 139ms/step - loss: 0.0291 - accuracy: 0.9932\\n",\
            "Epoch 21/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.0271 - accuracy: 0.9936\\n",\
            "Epoch 22/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.0303 - accuracy: 0.9927\\n",\
            "Epoch 23/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.0118 - accuracy: 0.9974\\n",\
            "Epoch 24/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0181 - accuracy: 0.9966\\n",\
            "Epoch 25/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.0173 - accuracy: 0.9967\\n",\
            "Epoch 26/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0146 - accuracy: 0.9973\\n",\
            "Epoch 27/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0134 - accuracy: 0.9976\\n",\
            "Epoch 28/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0166 - accuracy: 0.9970\\n",\
            "Epoch 29/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0179 - accuracy: 0.9964\\n",\
            "Epoch 30/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0113 - accuracy: 0.9978\\n",\
            "Epoch 31/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.0079 - accuracy: 0.9987\\n",\
            "Epoch 32/40\\n",\
            "350/350 [==============================] - 48s 139ms/step - loss: 0.0133 - accuracy: 0.9981\\n",\
            "Epoch 33/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0097 - accuracy: 0.9985\\n",\
            "Epoch 34/40\\n",\
            "350/350 [==============================] - 48s 139ms/step - loss: 0.0102 - accuracy: 0.9984\\n",\
            "Epoch 35/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0104 - accuracy: 0.9983\\n",\
            "Epoch 36/40\\n",\
            "350/350 [==============================] - 48s 139ms/step - loss: 0.0129 - accuracy: 0.9979\\n",\
            "Epoch 37/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.0127 - accuracy: 0.9983\\n",\
            "Epoch 38/40\\n",\
            "350/350 [==============================] - 48s 138ms/step - loss: 0.0055 - accuracy: 0.9991\\n",\
            "Epoch 39/40\\n",\
            "350/350 [==============================] - 48s 139ms/step - loss: 0.0127 - accuracy: 0.9983\\n",\
            "Epoch 40/40\\n",\
            "350/350 [==============================] - 49s 139ms/step - loss: 0.0112 - accuracy: 0.9985\\n"\
          ],\
          "name": "stdout"\
        \}\
      ]\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "J3U-2paXBpTS"\
      \},\
      "source": [\
        "model.save_weights('/content/gdrive/My Drive/weights_for_CCR')"\
      ],\
      "execution_count": null,\
      "outputs": []\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "l3Ue03Od62Qi",\
        "outputId": "537da4af-73c7-4d35-f755-f25b669d6c2a",\
        "colab": \{\
          "base_uri": "https://localhost:8080/",\
          "height": 35\
        \}\
      \},\
      "source": [\
        "output = model.predict(ds_test, verbose=1)"\
      ],\
      "execution_count": null,\
      "outputs": [\
        \{\
          "output_type": "stream",\
          "text": [\
            "    651/Unknown - 34s 51ms/step"\
          ],\
          "name": "stdout"\
        \}\
      ]\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "aB2k--JF8m8x",\
        "outputId": "d5a3498c-53bf-4570-fe1a-d942459031bb",\
        "colab": \{\
          "base_uri": "https://localhost:8080/",\
          "height": 204\
        \}\
      \},\
      "source": [\
        "answer = [decoder[np.argmax(i)] for i in output]\\n",\
        "out = pd.DataFrame(zip(np.arange(1, len(answer) + 1), answer), index=None, columns=['Id', 'Category'])\\n",\
        "out.to_csv('submission_CCR', index=False)\\n",\
        "out.head()"\
      ],\
      "execution_count": null,\
      "outputs": [\
        \{\
          "output_type": "execute_result",\
          "data": \{\
            "text/html": [\
              "<div>\\n",\
              "<style scoped>\\n",\
              "    .dataframe tbody tr th:only-of-type \{\\n",\
              "        vertical-align: middle;\\n",\
              "    \}\\n",\
              "\\n",\
              "    .dataframe tbody tr th \{\\n",\
              "        vertical-align: top;\\n",\
              "    \}\\n",\
              "\\n",\
              "    .dataframe thead th \{\\n",\
              "        text-align: right;\\n",\
              "    \}\\n",\
              "</style>\\n",\
              "<table border=\\"1\\" class=\\"dataframe\\">\\n",\
              "  <thead>\\n",\
              "    <tr style=\\"text-align: right;\\">\\n",\
              "      <th></th>\\n",\
              "      <th>Id</th>\\n",\
              "      <th>Category</th>\\n",\
              "    </tr>\\n",\
              "  </thead>\\n",\
              "  <tbody>\\n",\
              "    <tr>\\n",\
              "      <th>0</th>\\n",\
              "      <td>1</td>\\n",\
              "      <td>63955</td>\\n",\
              "    </tr>\\n",\
              "    <tr>\\n",\
              "      <th>1</th>\\n",\
              "      <td>2</td>\\n",\
              "      <td>64432</td>\\n",\
              "    </tr>\\n",\
              "    <tr>\\n",\
              "      <th>2</th>\\n",\
              "      <td>3</td>\\n",\
              "      <td>64709</td>\\n",\
              "    </tr>\\n",\
              "    <tr>\\n",\
              "      <th>3</th>\\n",\
              "      <td>4</td>\\n",\
              "      <td>64177</td>\\n",\
              "    </tr>\\n",\
              "    <tr>\\n",\
              "      <th>4</th>\\n",\
              "      <td>5</td>\\n",\
              "      <td>61881</td>\\n",\
              "    </tr>\\n",\
              "  </tbody>\\n",\
              "</table>\\n",\
              "</div>"\
            ],\
            "text/plain": [\
              "   Id  Category\\n",\
              "0   1     63955\\n",\
              "1   2     64432\\n",\
              "2   3     64709\\n",\
              "3   4     64177\\n",\
              "4   5     61881"\
            ]\
          \},\
          "metadata": \{\
            "tags": []\
          \},\
          "execution_count": 21\
        \}\
      ]\
    \},\
    \{\
      "cell_type": "code",\
      "metadata": \{\
        "id": "2_YVE4GREaLb"\
      \},\
      "source": [\
        ""\
      ],\
      "execution_count": null,\
      "outputs": []\
    \}\
  ]\
\}}